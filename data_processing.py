# -*- coding: utf-8 -*-
"""Copy of Data_Processing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1id2n1FMo0zFdOM0795JGRmughOo7b8rP
"""

#Run this cell to download the Landsat-8 data from the multi-earth 2023 website to your local drive
! wget 'https://rainforestchallenge.blob.core.windows.net/multiearth2023-dataset-final/landsat8_train.nc' -O ['path to location where you want to store data']

"""# **Setting up the Data**

For setting up the data multi-earth challenge dataset, the tools from the following GitHub repository have been used: [https://github.com/MIT-AI-Accelerator/multiearth-challenge](https://github.com/MIT-AI-Accelerator/multiearth-challenge)
"""

# Commented out IPython magic to ensure Python compatibility.
#cloning the multi-earth challeneg repsoirtory which has the tools for working with remote sensing data provided as part of the challenge
!git clone https://github.com/MIT-AI-Accelerator/multiearth-challenge
# %cd multiearth-challenge
!pip install .

# Commented out IPython magic to ensure Python compatibility.
#Importing relevant libraries
import pkg_resources

from matplotlib import pyplot as plt
import numpy as np

from multiearth_challenge.datasets import segmentation_dataset as sd

# %matplotlib inline
# %load_ext autoreload
# %autoreload 2

# Set data paths to Landsat-8 satellite imagery and ground truth deforestation labels stored in google drive
source_files = ["path to location where satellite data is stored"]
segmentation_files = ["path to location where ground-truth deforestation masks are stored"]

#selecting the source bands which I plan to use to train the model
source_bands = {"Landsat-8": ['SR_B2', 'SR_B3', 'SR_B4']} # RGB visible bands

#Using the tools as part of the multi-earth challenge to pre-process the satellite imagery

# If True, returned source images will have multiple channels in increasing order of frequency (e.g., red, green, blue for visible), co-pol before cross-pol, and with bands not originating from collected imagery coming last and in alphabetical order.
# The metadata returned with the imagery will also specify the channel order. If False, each band is treated as a separate sample.
merge_source_bands = False # bool

# The minimum and maximum allowable cloud coverage allowed in visible and IR imagery as a fraction [0, 1].
# Setting the maximum above 0 may be useful when incorporating SAR imagery into a multimodal model where a large fraction of cloud coverage may be acceptable.
# Similarly, evaluation in challenging cases with a minimum on the amount of cloud coverage may be desired.
# Note, there may be some innacuracies in the identified cloud coverage provided by the sensor's QA bands. This is especially true for Sentinel-2 data.
source_cloud_coverage = (0.0, 0.0) # Tuple[float, float]

# The minimum and maximum inclusive relative time window in days around the segmentation image from which source imagery is pulled.
# If the minimum is None, there is no filter on the minimum relative date. Similarly, no maximum can be specified with a value of None.
# For example, with a value of (-7, 7) only source imagery within the interval of -7 days before and 7 days after a segmentation image date will be returned as source imagery.
source_date_window = (-7, 7) # Tuple[Optional[float], Optional[float]]

# If True, for each target image only a single source image is returned in a unique pair. A single source image may be paired with multiple target images and vice-versa depending on data filters applied.
# If False, each target image is returned with all source images at the same location that satisfy applied data filters. This may be useful if you want to include information from multiple images when making a single segmentation prediction.
single_source_image = True

# If True, if no source or target image remain after data filtering, raise a ValueError, otherwise this dataset will have length 0.
error_on_empty = True # bool

# Creating a dataset of selected source bands and selected preprocessing steps
merge_source_bands = True
dataset_merged_bands = sd.ImageSegmentationDataset(
    source_files,
    segmentation_files,
    source_bands,
    merge_source_bands,
    source_cloud_coverage,
    source_date_window,
    single_source_image,
    error_on_empty,
)

# Checking the number of merged images (RGB composites) in the dataset
print(f"Number of merged band dataset samples: {len(dataset_merged_bands)}")

# Checking the dimensions of the merged images (RGB composites)
source_data_merged_bands, target_data_merged_bands = dataset_merged_bands[0]
print(f"Shape of the source image with merged bands: {source_data_merged_bands[0]['image'].shape}")
print(f"List of bands associated with the multi-band source image: {source_data_merged_bands[0]['bands']}") # This list corresponds to the channels in the image with the first band corresponding to channel index 0, the second channel index 1, etc.

# Resizing the RGB image to 128x128. The original image size is 85x85, which is not ideal to work with, when training a CNN architecture

import cv2
n_samples = 6000
X_train = np.zeros((n_samples,85,85,3))

for i in range(n_samples):
  X_train[i,...] = np.transpose(dataset_merged_bands[i][0][0]['image'])

Y_train = np.zeros((n_samples,256,256,1))

for i in range(n_samples):
  Y_train[i,...] = np.transpose(dataset_merged_bands[i][1]['image'])

#resizing images to 128x128x3
X_train = np.array([cv2.resize(img, (128, 128), interpolation=cv2.INTER_CUBIC) for img in X_train])

#reshaping the X-train array
X_train = np.transpose(X_train, (0,3,1,2))

#plotting the processed satellite image
plt.imshow(X_train[10,0,:,:],aspect='auto')

#plotting the processed deforestation mask
Y_train = np.array([cv2.resize(img, (128, 128), interpolation=cv2.INTER_NEAREST) for img in Y_train])
plt.imshow(Y_train[10,:,:],aspect='auto')

np.save("/content/drive/MyDrive/CS230_project/Data/X_train_6000", X_train)
np.save("/content/drive/MyDrive/CS230_project/Data/Y_train_6000", Y_train)